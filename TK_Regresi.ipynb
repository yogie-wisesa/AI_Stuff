{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intense-dialogue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chart_studio.plotly as py\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polar-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawMissing(df):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weighted-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = mx + b\n",
    "class gradient:\n",
    "    def __init__(self, m, b):\n",
    "        self.m = m\n",
    "        self.b = b\n",
    "        \n",
    "    def value(self, x):\n",
    "        return self.m * x + self.b\n",
    "    \n",
    "def cost_function(x, y, gradient):\n",
    "    sum = 0\n",
    "    total_sample = x.shape[0]\n",
    "    for i in range(total_sample):\n",
    "        real = y[i]\n",
    "        hypothesis = gradient.value(x[i])\n",
    "        sum += (hypothesis - real)**2\n",
    "    return np.sum(sum / (2 * total_sample))\n",
    "\n",
    "def JmDerivative(x, y, gradient):\n",
    "    sum = 0\n",
    "    total_sample = x.shape[0]\n",
    "    for i in range(total_sample):\n",
    "        real = y[i]\n",
    "        hypothesis = gradient.value(x[i])\n",
    "        sum += (hypothesis - real) * x[i]\n",
    "    return np.sum(sum / total_sample)\n",
    "\n",
    "def JbDerivative(x, y, gradient):\n",
    "    sum = 0\n",
    "    total_sample = x.shape[0]\n",
    "    for i in range(total_sample):\n",
    "        real = y[i]\n",
    "        hypothesis = gradient.value(x[i])\n",
    "        sum += hypothesis - real\n",
    "    return np.sum(sum / total_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "married-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(x, y, m=0, mStep=0.1, mTry=1000, b=0, bStep=0.1, bTry=1000): \n",
    "    costBest = sys.maxsize\n",
    "    gradientBest = None\n",
    "    for i in range(mTry):\n",
    "        for j in range(bTry):\n",
    "            mTest = m + mStep * i\n",
    "            bTest = b + bStep * j\n",
    "            result = cost_function(x, y, gradient(mTest, bTest))\n",
    "            if (result < costBest):\n",
    "                costBest = result\n",
    "                gradientBest = gradient(mTest, bTest)\n",
    "                # 0 is the best cost we can get, so return anyway\n",
    "                if (result == 0): return gradientBest\n",
    "    return gradientBest\n",
    "\n",
    "def BatchGD(x, y, m, b, learningRate, iter):\n",
    "    mList = []\n",
    "    bList = []\n",
    "    cList = []\n",
    "    for i in range(iter):\n",
    "        derivative_cost_m = JmDerivative(x, y, gradient(m, b))\n",
    "        derivative_cost_b = JbDerivative(x, y, gradient(m, b))\n",
    "        m = m - learningRate * derivative_cost_m\n",
    "        b = b - learningRate * derivative_cost_b\n",
    "        c = cost_function(x, y, gradient(m, b))\n",
    "        mList.append(m)\n",
    "        bList.append(b)\n",
    "        cList.append(c)\n",
    "    return mList, bList, cList\n",
    "\n",
    "def StochasticGD(x, y, m, b, learningRate):\n",
    "    \n",
    "    def CostDerivative(x1, y1, m, b, biasDerivative=False):\n",
    "        hypothesis = gradient(m, b).value(x1)\n",
    "        if (biasDerivative):\n",
    "            return np.sum(hypothesis - y1)\n",
    "        return np.sum((hypothesis - y1) * x1)\n",
    "    \n",
    "    mList = []\n",
    "    bList = []\n",
    "    cList = []\n",
    "    total_sample = x.shape[0]\n",
    "    for i in range(total_sample):\n",
    "        derivative_m = CostDerivative(x[i], y[i], m, b, False)\n",
    "        derivative_b = CostDerivative(x[i], y[i], m, b, True)\n",
    "        m = m - learningRate * derivative_m\n",
    "        b = b - learningRate * derivative_b\n",
    "        c = cost_function(x, y, gradient(m, b))\n",
    "        mList.append(m)\n",
    "        bList.append(b)\n",
    "        cList.append(c)\n",
    "    return mList, bList, cList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mechanical-oliver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  Percent\n",
       "OverallCond      0      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datacsv  = pd.read_csv('input/house/train.csv')\n",
    "dataset  = pd.DataFrame(datacsv, columns = ['OverallCond'])\n",
    "targets  = pd.DataFrame(datacsv, columns = ['SalePrice'])\n",
    "\n",
    "missing_dataset = DrawMissing(dataset)\n",
    "display(missing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "radical-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OverallCond\n",
      "0            5\n",
      "1            8\n",
      "2            5\n",
      "3            5\n",
      "4            5\n",
      "   SalePrice\n",
      "0     208500\n",
      "1     181500\n",
      "2     223500\n",
      "3     140000\n",
      "4     250000\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head())\n",
    "print(targets.head())\n",
    "\n",
    "targets = targets.to_numpy()\n",
    "dataset = dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-teddy",
   "metadata": {},
   "source": [
    "### Regresi Metode Statistika "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-report",
   "metadata": {},
   "source": [
    "#### Paramaters for Guessing Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stuffed-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "mStart = 10\n",
    "mStep  = 0.5\n",
    "mIter  = 100\n",
    "bStart = 50000\n",
    "bStep  = 10000\n",
    "bIter  = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = LinearRegression(dataset, targets, mStart, mStep, mIter, bStart, bStep, bIter)\n",
    "\n",
    "minIndex = np.argmin(dataset)\n",
    "maxIndex = np.argmax(dataset)\n",
    "\n",
    "xGrad = [dataset[minIndex], dataset[maxIndex]]\n",
    "yGrad = [best.value(dataset[minIndex]), best.value(dataset[maxIndex])]\n",
    "\n",
    "print(\"Cost: \", cost_function(dataset, targets, best))\n",
    "print(\"m: \", best.m)\n",
    "print(\"b: \", best.b)\n",
    "\n",
    "plt.scatter(dataset, targets, label='Data')\n",
    "plt.plot(xGrad, yGrad, color='Red', label='y = mx + b')\n",
    "plt.xlabel(\"X (Input)\")\n",
    "plt.ylabel(\"Y (Output)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-bacteria",
   "metadata": {},
   "source": [
    "#### Parameters for Using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.01\n",
    "iteration = 100\n",
    "mStart = 10\n",
    "bStart = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-blues",
   "metadata": {},
   "source": [
    "### Regresi Metode Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b, cost = BatchGD(dataset, targets, mStart, bStart, learningRate, iteration)\n",
    "\n",
    "minIndex = np.argmin(cost)\n",
    "print(\"Minimum Cost: \", cost[minIndex])\n",
    "print(\"m: \", m[minIndex])\n",
    "print(\"b: \", b[minIndex])\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(m, b, cost, 'Red')\n",
    "ax.set_xlabel('Weight (m)')\n",
    "ax.set_ylabel('Bias (b)')\n",
    "ax.set_zlabel('Cost (J)')\n",
    "ax.set_title('Batch Gradient Descent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-carry",
   "metadata": {},
   "source": [
    "### Regresi Stokastik Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b, cost = StochasticGD(dataset, targets, mStart, bStart, learningRate)\n",
    "\n",
    "minIndex = np.argmin(cost)\n",
    "print(\"Minimum Cost: \", cost[minIndex])\n",
    "print(\"m: \", m[minIndex])\n",
    "print(\"b: \", b[minIndex])\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(m, b, cost, 'Red')\n",
    "ax.set_xlabel('Weight (m)')\n",
    "ax.set_ylabel('Bias (b)')\n",
    "ax.set_zlabel('Cost (J)')\n",
    "ax.set_title('Batch Gradient Descent')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
